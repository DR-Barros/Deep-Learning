{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c_V7s6bLhBNM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsDX96BLhBNb"
   },
   "source": [
    "# TAREA 2\n",
    "\n",
    "**Adapted from:** [Nathan Inkawhich](https://github.com/inkawhich)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2u6reyuNaA5"
   },
   "source": [
    "In this task, we will look at how to create a model for image classification, the impact of transfer learning using models pretrained on the 1000-class Imagenet dataset. The most efficient parameters for each architectures are likely to change, so you must look at the existing architecture and make custom adjustments for each model.\n",
    "\n",
    "We will try to learn using a model **trained from scratch**, to do **feature extraction** by using only the last layer of a pre-trained network and only update the final layer weights using our data and label (i.e., using the CNN as a fixed feature extractor), and to **fine-tune** a pretrained model and update *all* of the model’s parameters for our task.\n",
    "\n",
    "More information about transfer learning [in the CS231n class of Standford](https://cs231n.github.io/transfer-learning/) and in [Sebastian Ruder's blog post](https://ruder.io/transfer-learning/).\n",
    "\n",
    "### Goal\n",
    "\n",
    "The goals for you are to\n",
    "* Fill up the code at different points where you have `# TODO`,\n",
    "* Try different hyper-parameters of the models, different training and evaluation settings in order to answer the questions\n",
    "* In the end you will have to upload an image of yours to test your model on it!    \n",
    "\n",
    "### Data\n",
    "\n",
    "We will use an Emotion Recognition dataset derived from FlickR30k. It is available at [this link](https://www.dcc.uchile.cl/~vbarrier/Flicker_data). It is composed of images that have been automatically tagged with several different emotions: `amusement, anger, awe, contentment, disgust, excitement, fear, sadness`.\n",
    "\n",
    "Download the data and set them in your google drive. The ``model_name`` input is the name of the model you wish to use and must\n",
    "be selected from this list:\n",
    "```python\n",
    "['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E_1n1ozfhBNi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.4.1+cu124\n",
      "Torchvision Version:  0.19.1+cpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TBP46zohBNr"
   },
   "source": [
    "### Inputs\n",
    "   \n",
    "The other inputs are as follows:\n",
    "* ``num_classes`` is the number of classes in the dataset, which is 8 in our case\n",
    "* ``batch_size`` is the batch size used for training and may be adjusted according to the capability of your machine, ``num_epochs`` is the number of training epochs we want to run,\n",
    "* ``feature_extract`` is a boolean that defines if we are finetuning or feature extracting. If ``feature_extract = False``, the model is finetuned and all model parameters are updated. If ``feature_extract = True``, only the last layer parameters are updated, the others remain fixed\n",
    "* `lr` which is the learning rate of the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "THFRLkjIhBNs"
   },
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"../Flicker_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"efficientnet_b2\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 8\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 12\n",
    "\n",
    "# learning rate of the optimizer\n",
    "lr=0.001\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "\n",
    "# Flag for data augmentation. When True apply a random cropped, a random\n",
    "#   flip on the training images, and a rotation.\n",
    "data_augmentation = True\n",
    "\n",
    "# if we want to top-N results;\n",
    "#   set an integer if want the top-3 results for example, set None if not wanted\n",
    "topNresults = 3\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kJA9MG1hBOT"
   },
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "Now that we know what the input size must be, we can initialize the data\n",
    "transforms, image datasets, and the dataloaders. Notice, the models were\n",
    "pretrained with the hard-coded normalization values, as described\n",
    "[here](https://pytorch.org/docs/master/torchvision/models.html).\n",
    "\n",
    "\n",
    "Two options to load the data:\n",
    "* Option 1: Download the dataset, and put it directly in your Google Drive that you can access through colab. **This is better as you do not need to download the data everytime you are intiating a new colab instance. You will also be able to save your best model!**\n",
    "* Option 2: Download the dataset directly on the colab instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khpEZ5iHZtCQ"
   },
   "source": [
    "#### Option 1: Use the dataset already in my Google Drive\n",
    "\n",
    "Here I am using as path of the project `'/content/drive/My Drive/DATASETS/deepemotion/'` where I should put the [dataset](https://users.dcc.uchile.cl/~vbarrier/Flicker_data/) `Flicker_data`. It means that I have it in my google drive under the path `'DATASETS/deepemotion/'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akPZvEU3NaA6"
   },
   "source": [
    "#### Option 2: Download the data directly here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SqmNzAshBN1"
   },
   "source": [
    "Helper Functions\n",
    "----------------\n",
    "\n",
    "Before we write the code for adjusting the models, lets define a few\n",
    "helper functions.\n",
    "\n",
    "**Model Training and Validation Code**\n",
    "\n",
    "The ``train_model`` function handles the training and validation of a\n",
    "given model. As input, it takes a PyTorch model, a dictionary of\n",
    "dataloaders, a loss function, an optimizer, a specified number of epochs\n",
    "to train and validate for, and a boolean flag for when the model is an\n",
    "Inception model.\n",
    "The function trains for the specified number of epochs and after each\n",
    "epoch runs a full validation step. It also keeps track of the best\n",
    "performing model (in terms of validation accuracy), and at the end of\n",
    "training returns the best performing model. After each epoch, the\n",
    "training and validation accuracies are printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lC7uzhp-hBN9"
   },
   "outputs": [],
   "source": [
    "def update_lists_for_f1_score(preds, labels, target_true, predicted_true, correct_true, all_labels):\n",
    "  \"\"\"\n",
    "  Need to be executed at every batch in order to update the lists target_true, predicted_true and correct_true.\n",
    "  target = TP + FN\n",
    "  predicted_true = TP + FP\n",
    "  correct_true = TP\n",
    "  \"\"\"\n",
    "  # iterating over all the classes\n",
    "  for class_k in all_labels:\n",
    "    predicted_classes = preds == class_k\n",
    "    target_classes = labels == class_k\n",
    "    target_true[class_k] += torch.sum(target_classes).float()\n",
    "    predicted_true[class_k] += torch.sum(predicted_classes).float()\n",
    "    correct_true[class_k] += torch.sum(\n",
    "        (predicted_classes) * (target_classes)).float()\n",
    "  return target_true, predicted_true, correct_true\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10,\n",
    "                   use_tqdm=False, name_model = 'best_model_no_feature_extraction.pt'):\n",
    "    since = time.time()\n",
    "    t0 = since\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # to initialize the counters of the true\n",
    "    dico_labels = image_datasets['val'].class_to_idx\n",
    "    dico_labels_inverse = {v:k for k, v in dico_labels.items()}\n",
    "    all_labels = dico_labels.values()\n",
    "    dict_true_init = {idx_lab : 0 for idx_lab in all_labels}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            # Set model to training/evaluate mode\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            target_true = dict_true_init.copy()\n",
    "            predicted_true = dict_true_init.copy()\n",
    "            correct_true = dict_true_init.copy()\n",
    "\n",
    "            # Iterate over data.\n",
    "            array_for_loop = dataloaders[phase]\n",
    "            if use_tqdm or (epoch == 0): # training is slow at 1st epoch\n",
    "              array_for_loop = tqdm(array_for_loop)\n",
    "            for inputs, labels in array_for_loop:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                # TODO\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # TODO\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # create predictions\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    # TODO\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                target_true, predicted_true, correct_true = update_lists_for_f1_score(preds, labels.data,\n",
    "                                                    target_true, predicted_true, correct_true, all_labels)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # calculating F1\n",
    "            recall = []\n",
    "            precision = []\n",
    "            f1_score = []\n",
    "            # At the end of the epoch\n",
    "            for k_class in range(len(set(all_labels))):\n",
    "                recall.append(correct_true[k_class] / target_true[k_class])\n",
    "                precision.append(correct_true[k_class] / predicted_true[k_class])\n",
    "                f1_score.append(2 * precision[k_class] * recall[k_class] / (precision[k_class] + recall[k_class]))\n",
    "\n",
    "            epoch_f1 = np.mean([k.cpu().numpy() for k in f1_score])\n",
    "\n",
    "            time_epoch = time.time()-t0\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}  F1: {:.4f} in {:.0f}m {:.0f}s'.format(phase, epoch_loss, epoch_acc,\n",
    "                                                                          epoch_f1, time_epoch // 60, time_epoch % 60))\n",
    "\n",
    "\n",
    "            # deep copy the model if best accuracy in this epoch\n",
    "            if phase == 'val':\n",
    "                str_to_write = 'F1 : '\n",
    "                for k, v in dico_labels.items():\n",
    "                    str_to_write += \"'{}' : {:.4f}, \".format(k, f1_score[v])\n",
    "                print(str_to_write)\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    print('Best model saved')\n",
    "                    torch.save(model, 'temp_' + name_model)\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            t0 = time.time()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaPjmM3rhBOE"
   },
   "source": [
    "#### Set Model Parameters’ .requires_grad attribute\n",
    "\n",
    "This helper function sets the ``.requires_grad`` attribute of the\n",
    "parameters in the model to False when we are feature extracting. By\n",
    "default, when we load a pretrained model all of the parameters have\n",
    "``.requires_grad=True``, which is fine if we are training from scratch\n",
    "or finetuning. However, if we are feature extracting and only want to\n",
    "compute gradients for the newly initialized layer then we want all of\n",
    "the other parameters to not require gradients. This will make more sense\n",
    "later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LTgRN1brhBOG"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4GkPUg-UhBON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
      "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
      "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
      "            (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2dNormActivation(\n",
      "      (0): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=True)\n",
      "    (1): Linear(in_features=1408, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Documents\\GitHub\\Deep-Learning\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Daniel\\Documents\\GitHub\\Deep-Learning\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"efficientnet_b2\":\n",
    "        \"\"\" Efficientnet\n",
    "        \"\"\"\n",
    "        model_ft = models.efficientnet_b2(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxfoYgVxh5gV"
   },
   "source": [
    "## Creation Datasets and Dataloaders\n",
    "\n",
    "Regarding Data Augmentation, use `transforms.RandomResizedCrop` and `transforms.RandomHorizontalFlip`, and also `transforms.RandomRotation` to see which one works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3UsoBlYihBOi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders with data augmentation...\n"
     ]
    }
   ],
   "source": [
    "def return_datasets_dataloaders(data_dir, input_size=224, angle_rotation=5, data_augmentation = True):\n",
    "    \"\"\"\n",
    "    Create the datasets and dataloaders needed for the training\n",
    "    \"\"\"\n",
    "\n",
    "    # apply data augmentation\n",
    "    list_data_transform_data_aug = [\n",
    "            # TODO\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(angle_rotation),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]\n",
    "    # test without data_augmentation\n",
    "    list_data_transform = [\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    if data_augmentation:\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose(list_data_transform_data_aug),\n",
    "            'val': transforms.Compose(list_data_transform),\n",
    "        }\n",
    "    else: # no data augmentation in this case\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose(list_data_transform),\n",
    "            'val': transforms.Compose(list_data_transform),\n",
    "        }\n",
    "\n",
    "\n",
    "    print(\"Initializing Datasets and Dataloaders\"+data_augmentation*\" with data augmentation\"+\"...\")\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "    # Create training and validation dataloaders\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "    return image_datasets, dataloaders_dict\n",
    "\n",
    "image_datasets, dataloaders_dict = return_datasets_dataloaders(data_dir, data_augmentation = data_augmentation)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akF_owSChBOo"
   },
   "source": [
    "Create the Optimizer\n",
    "--------------------\n",
    "\n",
    "Now that the model structure is correct, the final step for finetuning\n",
    "and feature extracting is to create an optimizer that only updates the\n",
    "desired parameters. Recall that after loading the pretrained model, but\n",
    "before reshaping, if ``feature_extract=True`` we manually set all of the\n",
    "parameter’s ``.requires_grad`` attributes to False. Then the\n",
    "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
    "default. So now we know that *all parameters that have\n",
    ".requires_grad=True should be optimized.* Next, we make a list of such\n",
    "parameters and input this list to the SGD algorithm constructor.\n",
    "\n",
    "To verify this, check out the printed parameters to learn. When\n",
    "finetuning, this list should be long and include all of the model\n",
    "parameters. However, when feature extracting this list should be short\n",
    "and only include the weights and biases of the reshaped layers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BMyU60MIhBOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.0.0.weight\n",
      "\t features.0.1.weight\n",
      "\t features.0.1.bias\n",
      "\t features.1.0.block.0.0.weight\n",
      "\t features.1.0.block.0.1.weight\n",
      "\t features.1.0.block.0.1.bias\n",
      "\t features.1.0.block.1.fc1.weight\n",
      "\t features.1.0.block.1.fc1.bias\n",
      "\t features.1.0.block.1.fc2.weight\n",
      "\t features.1.0.block.1.fc2.bias\n",
      "\t features.1.0.block.2.0.weight\n",
      "\t features.1.0.block.2.1.weight\n",
      "\t features.1.0.block.2.1.bias\n",
      "\t features.1.1.block.0.0.weight\n",
      "\t features.1.1.block.0.1.weight\n",
      "\t features.1.1.block.0.1.bias\n",
      "\t features.1.1.block.1.fc1.weight\n",
      "\t features.1.1.block.1.fc1.bias\n",
      "\t features.1.1.block.1.fc2.weight\n",
      "\t features.1.1.block.1.fc2.bias\n",
      "\t features.1.1.block.2.0.weight\n",
      "\t features.1.1.block.2.1.weight\n",
      "\t features.1.1.block.2.1.bias\n",
      "\t features.2.0.block.0.0.weight\n",
      "\t features.2.0.block.0.1.weight\n",
      "\t features.2.0.block.0.1.bias\n",
      "\t features.2.0.block.1.0.weight\n",
      "\t features.2.0.block.1.1.weight\n",
      "\t features.2.0.block.1.1.bias\n",
      "\t features.2.0.block.2.fc1.weight\n",
      "\t features.2.0.block.2.fc1.bias\n",
      "\t features.2.0.block.2.fc2.weight\n",
      "\t features.2.0.block.2.fc2.bias\n",
      "\t features.2.0.block.3.0.weight\n",
      "\t features.2.0.block.3.1.weight\n",
      "\t features.2.0.block.3.1.bias\n",
      "\t features.2.1.block.0.0.weight\n",
      "\t features.2.1.block.0.1.weight\n",
      "\t features.2.1.block.0.1.bias\n",
      "\t features.2.1.block.1.0.weight\n",
      "\t features.2.1.block.1.1.weight\n",
      "\t features.2.1.block.1.1.bias\n",
      "\t features.2.1.block.2.fc1.weight\n",
      "\t features.2.1.block.2.fc1.bias\n",
      "\t features.2.1.block.2.fc2.weight\n",
      "\t features.2.1.block.2.fc2.bias\n",
      "\t features.2.1.block.3.0.weight\n",
      "\t features.2.1.block.3.1.weight\n",
      "\t features.2.1.block.3.1.bias\n",
      "\t features.2.2.block.0.0.weight\n",
      "\t features.2.2.block.0.1.weight\n",
      "\t features.2.2.block.0.1.bias\n",
      "\t features.2.2.block.1.0.weight\n",
      "\t features.2.2.block.1.1.weight\n",
      "\t features.2.2.block.1.1.bias\n",
      "\t features.2.2.block.2.fc1.weight\n",
      "\t features.2.2.block.2.fc1.bias\n",
      "\t features.2.2.block.2.fc2.weight\n",
      "\t features.2.2.block.2.fc2.bias\n",
      "\t features.2.2.block.3.0.weight\n",
      "\t features.2.2.block.3.1.weight\n",
      "\t features.2.2.block.3.1.bias\n",
      "\t features.3.0.block.0.0.weight\n",
      "\t features.3.0.block.0.1.weight\n",
      "\t features.3.0.block.0.1.bias\n",
      "\t features.3.0.block.1.0.weight\n",
      "\t features.3.0.block.1.1.weight\n",
      "\t features.3.0.block.1.1.bias\n",
      "\t features.3.0.block.2.fc1.weight\n",
      "\t features.3.0.block.2.fc1.bias\n",
      "\t features.3.0.block.2.fc2.weight\n",
      "\t features.3.0.block.2.fc2.bias\n",
      "\t features.3.0.block.3.0.weight\n",
      "\t features.3.0.block.3.1.weight\n",
      "\t features.3.0.block.3.1.bias\n",
      "\t features.3.1.block.0.0.weight\n",
      "\t features.3.1.block.0.1.weight\n",
      "\t features.3.1.block.0.1.bias\n",
      "\t features.3.1.block.1.0.weight\n",
      "\t features.3.1.block.1.1.weight\n",
      "\t features.3.1.block.1.1.bias\n",
      "\t features.3.1.block.2.fc1.weight\n",
      "\t features.3.1.block.2.fc1.bias\n",
      "\t features.3.1.block.2.fc2.weight\n",
      "\t features.3.1.block.2.fc2.bias\n",
      "\t features.3.1.block.3.0.weight\n",
      "\t features.3.1.block.3.1.weight\n",
      "\t features.3.1.block.3.1.bias\n",
      "\t features.3.2.block.0.0.weight\n",
      "\t features.3.2.block.0.1.weight\n",
      "\t features.3.2.block.0.1.bias\n",
      "\t features.3.2.block.1.0.weight\n",
      "\t features.3.2.block.1.1.weight\n",
      "\t features.3.2.block.1.1.bias\n",
      "\t features.3.2.block.2.fc1.weight\n",
      "\t features.3.2.block.2.fc1.bias\n",
      "\t features.3.2.block.2.fc2.weight\n",
      "\t features.3.2.block.2.fc2.bias\n",
      "\t features.3.2.block.3.0.weight\n",
      "\t features.3.2.block.3.1.weight\n",
      "\t features.3.2.block.3.1.bias\n",
      "\t features.4.0.block.0.0.weight\n",
      "\t features.4.0.block.0.1.weight\n",
      "\t features.4.0.block.0.1.bias\n",
      "\t features.4.0.block.1.0.weight\n",
      "\t features.4.0.block.1.1.weight\n",
      "\t features.4.0.block.1.1.bias\n",
      "\t features.4.0.block.2.fc1.weight\n",
      "\t features.4.0.block.2.fc1.bias\n",
      "\t features.4.0.block.2.fc2.weight\n",
      "\t features.4.0.block.2.fc2.bias\n",
      "\t features.4.0.block.3.0.weight\n",
      "\t features.4.0.block.3.1.weight\n",
      "\t features.4.0.block.3.1.bias\n",
      "\t features.4.1.block.0.0.weight\n",
      "\t features.4.1.block.0.1.weight\n",
      "\t features.4.1.block.0.1.bias\n",
      "\t features.4.1.block.1.0.weight\n",
      "\t features.4.1.block.1.1.weight\n",
      "\t features.4.1.block.1.1.bias\n",
      "\t features.4.1.block.2.fc1.weight\n",
      "\t features.4.1.block.2.fc1.bias\n",
      "\t features.4.1.block.2.fc2.weight\n",
      "\t features.4.1.block.2.fc2.bias\n",
      "\t features.4.1.block.3.0.weight\n",
      "\t features.4.1.block.3.1.weight\n",
      "\t features.4.1.block.3.1.bias\n",
      "\t features.4.2.block.0.0.weight\n",
      "\t features.4.2.block.0.1.weight\n",
      "\t features.4.2.block.0.1.bias\n",
      "\t features.4.2.block.1.0.weight\n",
      "\t features.4.2.block.1.1.weight\n",
      "\t features.4.2.block.1.1.bias\n",
      "\t features.4.2.block.2.fc1.weight\n",
      "\t features.4.2.block.2.fc1.bias\n",
      "\t features.4.2.block.2.fc2.weight\n",
      "\t features.4.2.block.2.fc2.bias\n",
      "\t features.4.2.block.3.0.weight\n",
      "\t features.4.2.block.3.1.weight\n",
      "\t features.4.2.block.3.1.bias\n",
      "\t features.4.3.block.0.0.weight\n",
      "\t features.4.3.block.0.1.weight\n",
      "\t features.4.3.block.0.1.bias\n",
      "\t features.4.3.block.1.0.weight\n",
      "\t features.4.3.block.1.1.weight\n",
      "\t features.4.3.block.1.1.bias\n",
      "\t features.4.3.block.2.fc1.weight\n",
      "\t features.4.3.block.2.fc1.bias\n",
      "\t features.4.3.block.2.fc2.weight\n",
      "\t features.4.3.block.2.fc2.bias\n",
      "\t features.4.3.block.3.0.weight\n",
      "\t features.4.3.block.3.1.weight\n",
      "\t features.4.3.block.3.1.bias\n",
      "\t features.5.0.block.0.0.weight\n",
      "\t features.5.0.block.0.1.weight\n",
      "\t features.5.0.block.0.1.bias\n",
      "\t features.5.0.block.1.0.weight\n",
      "\t features.5.0.block.1.1.weight\n",
      "\t features.5.0.block.1.1.bias\n",
      "\t features.5.0.block.2.fc1.weight\n",
      "\t features.5.0.block.2.fc1.bias\n",
      "\t features.5.0.block.2.fc2.weight\n",
      "\t features.5.0.block.2.fc2.bias\n",
      "\t features.5.0.block.3.0.weight\n",
      "\t features.5.0.block.3.1.weight\n",
      "\t features.5.0.block.3.1.bias\n",
      "\t features.5.1.block.0.0.weight\n",
      "\t features.5.1.block.0.1.weight\n",
      "\t features.5.1.block.0.1.bias\n",
      "\t features.5.1.block.1.0.weight\n",
      "\t features.5.1.block.1.1.weight\n",
      "\t features.5.1.block.1.1.bias\n",
      "\t features.5.1.block.2.fc1.weight\n",
      "\t features.5.1.block.2.fc1.bias\n",
      "\t features.5.1.block.2.fc2.weight\n",
      "\t features.5.1.block.2.fc2.bias\n",
      "\t features.5.1.block.3.0.weight\n",
      "\t features.5.1.block.3.1.weight\n",
      "\t features.5.1.block.3.1.bias\n",
      "\t features.5.2.block.0.0.weight\n",
      "\t features.5.2.block.0.1.weight\n",
      "\t features.5.2.block.0.1.bias\n",
      "\t features.5.2.block.1.0.weight\n",
      "\t features.5.2.block.1.1.weight\n",
      "\t features.5.2.block.1.1.bias\n",
      "\t features.5.2.block.2.fc1.weight\n",
      "\t features.5.2.block.2.fc1.bias\n",
      "\t features.5.2.block.2.fc2.weight\n",
      "\t features.5.2.block.2.fc2.bias\n",
      "\t features.5.2.block.3.0.weight\n",
      "\t features.5.2.block.3.1.weight\n",
      "\t features.5.2.block.3.1.bias\n",
      "\t features.5.3.block.0.0.weight\n",
      "\t features.5.3.block.0.1.weight\n",
      "\t features.5.3.block.0.1.bias\n",
      "\t features.5.3.block.1.0.weight\n",
      "\t features.5.3.block.1.1.weight\n",
      "\t features.5.3.block.1.1.bias\n",
      "\t features.5.3.block.2.fc1.weight\n",
      "\t features.5.3.block.2.fc1.bias\n",
      "\t features.5.3.block.2.fc2.weight\n",
      "\t features.5.3.block.2.fc2.bias\n",
      "\t features.5.3.block.3.0.weight\n",
      "\t features.5.3.block.3.1.weight\n",
      "\t features.5.3.block.3.1.bias\n",
      "\t features.6.0.block.0.0.weight\n",
      "\t features.6.0.block.0.1.weight\n",
      "\t features.6.0.block.0.1.bias\n",
      "\t features.6.0.block.1.0.weight\n",
      "\t features.6.0.block.1.1.weight\n",
      "\t features.6.0.block.1.1.bias\n",
      "\t features.6.0.block.2.fc1.weight\n",
      "\t features.6.0.block.2.fc1.bias\n",
      "\t features.6.0.block.2.fc2.weight\n",
      "\t features.6.0.block.2.fc2.bias\n",
      "\t features.6.0.block.3.0.weight\n",
      "\t features.6.0.block.3.1.weight\n",
      "\t features.6.0.block.3.1.bias\n",
      "\t features.6.1.block.0.0.weight\n",
      "\t features.6.1.block.0.1.weight\n",
      "\t features.6.1.block.0.1.bias\n",
      "\t features.6.1.block.1.0.weight\n",
      "\t features.6.1.block.1.1.weight\n",
      "\t features.6.1.block.1.1.bias\n",
      "\t features.6.1.block.2.fc1.weight\n",
      "\t features.6.1.block.2.fc1.bias\n",
      "\t features.6.1.block.2.fc2.weight\n",
      "\t features.6.1.block.2.fc2.bias\n",
      "\t features.6.1.block.3.0.weight\n",
      "\t features.6.1.block.3.1.weight\n",
      "\t features.6.1.block.3.1.bias\n",
      "\t features.6.2.block.0.0.weight\n",
      "\t features.6.2.block.0.1.weight\n",
      "\t features.6.2.block.0.1.bias\n",
      "\t features.6.2.block.1.0.weight\n",
      "\t features.6.2.block.1.1.weight\n",
      "\t features.6.2.block.1.1.bias\n",
      "\t features.6.2.block.2.fc1.weight\n",
      "\t features.6.2.block.2.fc1.bias\n",
      "\t features.6.2.block.2.fc2.weight\n",
      "\t features.6.2.block.2.fc2.bias\n",
      "\t features.6.2.block.3.0.weight\n",
      "\t features.6.2.block.3.1.weight\n",
      "\t features.6.2.block.3.1.bias\n",
      "\t features.6.3.block.0.0.weight\n",
      "\t features.6.3.block.0.1.weight\n",
      "\t features.6.3.block.0.1.bias\n",
      "\t features.6.3.block.1.0.weight\n",
      "\t features.6.3.block.1.1.weight\n",
      "\t features.6.3.block.1.1.bias\n",
      "\t features.6.3.block.2.fc1.weight\n",
      "\t features.6.3.block.2.fc1.bias\n",
      "\t features.6.3.block.2.fc2.weight\n",
      "\t features.6.3.block.2.fc2.bias\n",
      "\t features.6.3.block.3.0.weight\n",
      "\t features.6.3.block.3.1.weight\n",
      "\t features.6.3.block.3.1.bias\n",
      "\t features.6.4.block.0.0.weight\n",
      "\t features.6.4.block.0.1.weight\n",
      "\t features.6.4.block.0.1.bias\n",
      "\t features.6.4.block.1.0.weight\n",
      "\t features.6.4.block.1.1.weight\n",
      "\t features.6.4.block.1.1.bias\n",
      "\t features.6.4.block.2.fc1.weight\n",
      "\t features.6.4.block.2.fc1.bias\n",
      "\t features.6.4.block.2.fc2.weight\n",
      "\t features.6.4.block.2.fc2.bias\n",
      "\t features.6.4.block.3.0.weight\n",
      "\t features.6.4.block.3.1.weight\n",
      "\t features.6.4.block.3.1.bias\n",
      "\t features.7.0.block.0.0.weight\n",
      "\t features.7.0.block.0.1.weight\n",
      "\t features.7.0.block.0.1.bias\n",
      "\t features.7.0.block.1.0.weight\n",
      "\t features.7.0.block.1.1.weight\n",
      "\t features.7.0.block.1.1.bias\n",
      "\t features.7.0.block.2.fc1.weight\n",
      "\t features.7.0.block.2.fc1.bias\n",
      "\t features.7.0.block.2.fc2.weight\n",
      "\t features.7.0.block.2.fc2.bias\n",
      "\t features.7.0.block.3.0.weight\n",
      "\t features.7.0.block.3.1.weight\n",
      "\t features.7.0.block.3.1.bias\n",
      "\t features.7.1.block.0.0.weight\n",
      "\t features.7.1.block.0.1.weight\n",
      "\t features.7.1.block.0.1.bias\n",
      "\t features.7.1.block.1.0.weight\n",
      "\t features.7.1.block.1.1.weight\n",
      "\t features.7.1.block.1.1.bias\n",
      "\t features.7.1.block.2.fc1.weight\n",
      "\t features.7.1.block.2.fc1.bias\n",
      "\t features.7.1.block.2.fc2.weight\n",
      "\t features.7.1.block.2.fc2.bias\n",
      "\t features.7.1.block.3.0.weight\n",
      "\t features.7.1.block.3.1.weight\n",
      "\t features.7.1.block.3.1.bias\n",
      "\t features.8.0.weight\n",
      "\t features.8.1.weight\n",
      "\t features.8.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTWYWU6uhBOy"
   },
   "source": [
    "Run Training and Validation Step\n",
    "--------------------------------\n",
    "\n",
    "Finally, the last step is to setup the loss for the model, then run the\n",
    "training and validation function for the set number of epochs. Notice,\n",
    "depending on the number of epochs this step may take a while on a CPU.\n",
    "Also, the default learning rate is not optimal for all of the models, so\n",
    "to achieve maximum accuracy it would be necessary to tune for each model\n",
    "separately.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMhug0jHhBOz",
    "outputId": "32d4184c-6e27-44d4-885f-513572d0f9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335/335 [09:48<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.5784 Acc: 0.4580  F1: 0.3144 in 9m 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.5665 Acc: 0.4501  F1: 0.4036 in 0m 6s\n",
      "F1 : 'amusement' : 0.6618, 'anger' : 0.0755, 'awe' : 0.7234, 'contentment' : 0.3503, 'disgust' : 0.4444, 'excitement' : 0.5000, 'fear' : 0.0417, 'sadness' : 0.4314, \n",
      "Best model saved\n",
      "\n",
      "Epoch 1/11\n",
      "----------\n",
      "train Loss: 1.2508 Acc: 0.5692  F1: 0.4427 in 10m 1s\n",
      "val Loss: 1.3744 Acc: 0.5243  F1: 0.4873 in 0m 5s\n",
      "F1 : 'amusement' : 0.6724, 'anger' : 0.2373, 'awe' : 0.7600, 'contentment' : 0.4567, 'disgust' : 0.5979, 'excitement' : 0.5345, 'fear' : 0.1569, 'sadness' : 0.4828, \n",
      "Best model saved\n",
      "\n",
      "Epoch 2/11\n",
      "----------\n",
      "train Loss: 1.1588 Acc: 0.5952  F1: 0.4876 in 9m 45s\n",
      "val Loss: 1.2815 Acc: 0.5422  F1: 0.5135 in 0m 5s\n",
      "F1 : 'amusement' : 0.6891, 'anger' : 0.2647, 'awe' : 0.7551, 'contentment' : 0.5156, 'disgust' : 0.5773, 'excitement' : 0.5607, 'fear' : 0.2456, 'sadness' : 0.5000, \n",
      "Best model saved\n",
      "\n",
      "Epoch 3/11\n",
      "----------\n",
      "train Loss: 1.1044 Acc: 0.6106  F1: 0.5237 in 10m 6s\n",
      "val Loss: 1.2361 Acc: 0.5754  F1: 0.5552 in 0m 5s\n",
      "F1 : 'amusement' : 0.6903, 'anger' : 0.3143, 'awe' : 0.7692, 'contentment' : 0.5323, 'disgust' : 0.6250, 'excitement' : 0.6226, 'fear' : 0.3582, 'sadness' : 0.5294, \n",
      "Best model saved\n",
      "\n",
      "Epoch 4/11\n",
      "----------\n",
      "train Loss: 1.0678 Acc: 0.6261  F1: 0.5428 in 9m 40s\n",
      "val Loss: 1.1929 Acc: 0.5703  F1: 0.5474 in 0m 5s\n",
      "F1 : 'amusement' : 0.7018, 'anger' : 0.3099, 'awe' : 0.7767, 'contentment' : 0.5366, 'disgust' : 0.6122, 'excitement' : 0.6154, 'fear' : 0.3175, 'sadness' : 0.5094, \n",
      "\n",
      "Epoch 5/11\n",
      "----------\n",
      "train Loss: 1.0497 Acc: 0.6312  F1: 0.5510 in 9m 52s\n",
      "val Loss: 1.1453 Acc: 0.5806  F1: 0.5604 in 0m 5s\n",
      "F1 : 'amusement' : 0.7143, 'anger' : 0.3636, 'awe' : 0.7647, 'contentment' : 0.5470, 'disgust' : 0.5918, 'excitement' : 0.6154, 'fear' : 0.3175, 'sadness' : 0.5688, \n",
      "Best model saved\n",
      "\n",
      "Epoch 6/11\n",
      "----------\n",
      "train Loss: 1.0145 Acc: 0.6414  F1: 0.5693 in 10m 21s\n",
      "val Loss: 1.1196 Acc: 0.5806  F1: 0.5634 in 0m 5s\n",
      "F1 : 'amusement' : 0.7143, 'anger' : 0.3243, 'awe' : 0.7692, 'contentment' : 0.5345, 'disgust' : 0.5859, 'excitement' : 0.6019, 'fear' : 0.3944, 'sadness' : 0.5825, \n",
      "\n",
      "Epoch 7/11\n",
      "----------\n",
      "train Loss: 0.9963 Acc: 0.6470  F1: 0.5783 in 10m 21s\n",
      "val Loss: 1.1022 Acc: 0.5882  F1: 0.5759 in 0m 5s\n",
      "F1 : 'amusement' : 0.7207, 'anger' : 0.3590, 'awe' : 0.7451, 'contentment' : 0.5455, 'disgust' : 0.5714, 'excitement' : 0.6186, 'fear' : 0.4507, 'sadness' : 0.5962, \n",
      "Best model saved\n",
      "\n",
      "Epoch 8/11\n",
      "----------\n",
      "train Loss: 0.9799 Acc: 0.6548  F1: 0.5881 in 10m 46s\n",
      "val Loss: 1.0809 Acc: 0.5985  F1: 0.5919 in 0m 5s\n",
      "F1 : 'amusement' : 0.7429, 'anger' : 0.4286, 'awe' : 0.7525, 'contentment' : 0.5246, 'disgust' : 0.5882, 'excitement' : 0.6598, 'fear' : 0.4789, 'sadness' : 0.5600, \n",
      "Best model saved\n",
      "\n",
      "Epoch 9/11\n",
      "----------\n",
      "train Loss: 0.9533 Acc: 0.6615  F1: 0.5943 in 12m 13s\n",
      "val Loss: 1.0695 Acc: 0.6010  F1: 0.5877 in 0m 5s\n",
      "F1 : 'amusement' : 0.7429, 'anger' : 0.3947, 'awe' : 0.7290, 'contentment' : 0.5505, 'disgust' : 0.5941, 'excitement' : 0.6476, 'fear' : 0.4507, 'sadness' : 0.5926, \n",
      "Best model saved\n",
      "\n",
      "Epoch 10/11\n",
      "----------\n",
      "train Loss: 0.9368 Acc: 0.6675  F1: 0.6031 in 11m 41s\n",
      "val Loss: 1.0567 Acc: 0.6113  F1: 0.6019 in 0m 5s\n",
      "F1 : 'amusement' : 0.7379, 'anger' : 0.4054, 'awe' : 0.7500, 'contentment' : 0.5546, 'disgust' : 0.6061, 'excitement' : 0.6346, 'fear' : 0.5128, 'sadness' : 0.6139, \n",
      "Best model saved\n",
      "\n",
      "Epoch 11/11\n",
      "----------\n",
      "train Loss: 0.9228 Acc: 0.6723  F1: 0.6089 in 12m 13s\n",
      "val Loss: 1.0503 Acc: 0.6113  F1: 0.6033 in 0m 5s\n",
      "F1 : 'amusement' : 0.7379, 'anger' : 0.4156, 'awe' : 0.7429, 'contentment' : 0.5470, 'disgust' : 0.5957, 'excitement' : 0.6667, 'fear' : 0.5385, 'sadness' : 0.5825, \n",
      "\n",
      "Training complete in 127m 52s\n",
      "Best val Acc: 0.611253\n"
     ]
    }
   ],
   "source": [
    "name_model = 'finetuned-efficientnet'+'.pt'\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs,\n",
    "                             use_tqdm=False, name_model = name_model)\n",
    "\n",
    "torch.save(model_ft, '{}/{}'.format(data_dir, name_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oie1IGXgBNL"
   },
   "source": [
    "#### Plot hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CIgIdifGBYq1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(hist):\n",
    "  \"\"\"\n",
    "  Plot the training curves of validation accuracy vs. number of training epochs\n",
    "  \"\"\"\n",
    "  ohist = []\n",
    "\n",
    "  ohist = [h.cpu().numpy() for h in hist]\n",
    "\n",
    "  plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "  plt.xlabel(\"Training Epochs\")\n",
    "  plt.ylabel(\"Validation Accuracy\")\n",
    "  plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "  # plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "  plt.ylim((0,1.))\n",
    "  plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7jWxpYuKyPk"
   },
   "source": [
    "### Some visualizations\n",
    "\n",
    "We keep one model under the name `'fine_tune_total_best_accuracy.pt'` that obtained the scores below so that we can check it's F1 score.\n",
    "\n",
    "Let's have a look at the model's predictions with\n",
    "* the confusion matrix to see between which class is the confusion\n",
    "* the top-N predictions to see if the model predict in which position it predicts the right class. It is important as emotion can be multi-class and are subjectives\n",
    "* A aggregation of the emotions regarding their valence (positiveness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBko7JXRNaA9"
   },
   "source": [
    "## Preguntas\n",
    "\n",
    "* Que pienses de la matriz de confusion?\n",
    "* Porque hace sentido de mirar la accuracy topN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH54mxUwNaA9"
   },
   "source": [
    "## Respuestas\n",
    "\n",
    "**Ponga tues respuestas aca**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpcMfmZ-AshS"
   },
   "source": [
    "### Test on our own images !\n",
    "\n",
    "Funny test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9eDC0EsNaA9"
   },
   "source": [
    "## Preguntas\n",
    "\n",
    "* Qué es un modelo pre-entrenado? Qué significa fine-tunear un modelo?\n",
    "* Cuáles son las diferencias principales entre entrenar un modelo desde cero y usar Transfer Learning?\n",
    "* Que pasa con las curvas de aprentizaje cuando utilizamos representaciones viniendo de un modelo ya pre-entrenado?\n",
    "* A qué hace referencia Layer Freezing? ¿Cuáles podrían ser las ventajas de hacer esto?\n",
    "* Cuales son las differencias entre extractar los atributos y fine-tunear la ultima capa o fine-tunear todos los parametros del red? Que pasa con las curvas de apprentizaje?\n",
    "* Cual es el efecto de la aumentacion de datos? Como se puede ver? Que pasa con las curvas de aprentizaje?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1PK4vgtNaA9"
   },
   "source": [
    "## Respuestas\n",
    "\n",
    "**Ponga tues respuestas aca**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
